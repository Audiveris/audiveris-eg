<!DOCTYPE html>
<html>
    <head>
        <title>
            Package omr.glyph.text
        </title>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    </head>
    <body>
        <p>
            Package for handling textual aspects in glyphs.
        </p>

        <h2>
            General model
        </h2>
        <p>
            <img src="doc-files/Text.jpg" alt="Text"
                 title="Text data model" />
        </p>
        
        <h2>
            How textual glyphs are handled
        </h2>
        <p>
            The text strategy has significantly evolved since the integration
            of new Tesseract OCR (version 3).
        </p>
        
        <h3>
            Detection of text items
        </h3>
        <p>
            The purpose of the TEXTS step is to run Tesseract OCR on a system
            image, before glyphs get further decomposed into stems and leaves.
            The OCR is thus performed on each system in parallel.
        </p>
        <p>
            We use the SegmentationMode.AUTO mode of OCR, which thus performs
            the image layout analysis and then interprets each of the detected 
            lines. 
            The OCR output (lines, words and chars) is then translated to 
            Audiveris TextLine, TextWord and TextChar instances which are
            recomposed (lines and words may get merged and split).
            The final TextLines are kept at SystemInfo level.
        </p>
        
        <h3>
            Detection of text-shaped glyphs
        </h3>
        <p>
            Later, in SYMBOLS step, some glyphs might be recognized as TEXT
            shaped glyphs (or have been manually assigned the TEXT shape).
            The OCR is then launched in SINGLE_BLOCK mode on just the glyph 
            image, and the resulting line is then recomposed with the other
            SystemInfo TextLine instances.
        </p>
    </body>
</html>
